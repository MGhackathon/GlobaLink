"""
ë‰´ìŠ¤ ê¸°ì‚¬ ìš”ì•½ ì‹œìŠ¤í…œ
OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ í¬ë¡¤ë§ëœ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ìš”ì•½
"""

import json
import os
from typing import List, Dict, Any, Optional
from datetime import datetime
import time
from openai import OpenAI
from dotenv import load_dotenv
import sys

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

sys.stdout.reconfigure(encoding='utf-8')


class NewsSummarizer:
    """OpenAIë¥¼ ì‚¬ìš©í•œ ë‰´ìŠ¤ ìš”ì•½ í´ë˜ìŠ¤"""
    
    def __init__(self, api_key: Optional[str] = None):
        """
        Args:
            api_key: OpenAI API í‚¤ (Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜´)
        """
        self.api_key = api_key or os.getenv('OPENAI_API_KEY')
        
        if not self.api_key:
            raise ValueError("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ê±°ë‚˜ api_key ë§¤ê°œë³€ìˆ˜ë¥¼ ì „ë‹¬í•˜ì„¸ìš”.")
        
        self.client = OpenAI(api_key=self.api_key)
        
        # ìš”ì•½ í”„ë¡¬í”„íŠ¸ ì„¤ì •
        self.system_prompt = """ë‹¹ì‹ ì€ ì „ë¬¸ ë‰´ìŠ¤ ì—ë””í„°ì…ë‹ˆë‹¤. 
ì£¼ì–´ì§„ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ì½ê³  í•µì‹¬ ë‚´ìš©ì„ ì§§ê³  ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”.

ìš”ì•½ ê·œì¹™:
1. 5-6ì¤„ ì´ë‚´ë¡œ í•µì‹¬ë§Œ ìš”ì•½
2. ê° ì¤„ì€ í•œ ë¬¸ì¥ìœ¼ë¡œ ì§§ê³  ê°„ê²°í•˜ê²Œ ì‘ì„±
3. ë¶ˆí•„ìš”í•œ ìˆ˜ì‹ì–´ë‚˜ ì ‘ì†ì‚¬ ìµœì†Œí™”
4. í•µì‹¬ í‚¤ì›Œë“œì™€ ì£¼ìš” ìˆ˜ì¹˜ë¥¼ í¬í•¨
5. ëª…ì‚¬í˜• ì¢…ê²°ì´ë‚˜ ì²´ì–¸ ì¢…ì§€ í™œìš©
6. ê°ê´€ì ì´ê³  íŒ©íŠ¸ ì¤‘ì‹¬ìœ¼ë¡œ ì‘ì„±

ì˜ˆì‹œ í˜•ì‹:
í˜„ëŒ€ì°¨ 5ì¼ ì£¼ê°€ 11% ê¸‰ë“±
ë¡œë´‡Â·ììœ¨ì£¼í–‰ ì–‘ë‚ ê°œë¡œ ì§ˆì£¼
ë³´ìŠ¤í„´ë‹¤ì´ë‚˜ë¯¹ìŠ¤ ê°€ì¹˜ ë¶€ê°
ììœ¨ì£¼í–‰ ë¹…í…Œí¬ í˜‘ì—…ë„ í˜¸ì¬
"""
        
        # í†µê³„
        self.stats = {
            'total_articles': 0,
            'success_count': 0,
            'error_count': 0,
            'total_tokens_used': 0,
            'total_cost': 0.0
        }
    
    def summarize_article(self, article: Dict[str, Any], max_tokens: int = 500) -> Dict[str, Any]:
        """
        ë‹¨ì¼ ê¸°ì‚¬ ìš”ì•½
        
        Args:
            article: ê¸°ì‚¬ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
            max_tokens: ìµœëŒ€ í† í° ìˆ˜
            
        Returns:
            ìš”ì•½ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            title = article.get('title', '')
            content = article.get('content', '')
            image_url = article.get('image_url', '')
            category = article.get('category', '')
            url = article.get('url', '')
            published_at = article.get('published_at', '')
            
            if not content or len(content.strip()) < 100:
                return {
                    'success': False,
                    'error': 'ê¸°ì‚¬ ë³¸ë¬¸ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤.',
                    'article_id': article.get('article_id', ''),
                    'image_url': image_url
                }
            
            # ë³¸ë¬¸ì´ ë„ˆë¬´ ê¸¸ë©´ ì¼ë¶€ë§Œ ì‚¬ìš© (GPT-3.5-turbo í† í° ì œí•œ ê³ ë ¤)
            if len(content) > 8000:
                content = content[:8000] + "..."
            
            # ìš”ì•½ ìš”ì²­
            user_prompt = f"ì œëª©: {title}\n\në³¸ë¬¸:\n{content}"
            
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=max_tokens,
                temperature=0.3,
                top_p=1.0,
                frequency_penalty=0.0,
                presence_penalty=0.0
            )
            
            summary = response.choices[0].message.content.strip()
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            tokens_used = response.usage.total_tokens
            self.stats['total_tokens_used'] += tokens_used
            self.stats['success_count'] += 1
            
            # ë¹„ìš© ê³„ì‚° (GPT-3.5-turbo ê¸°ì¤€: input $0.0015/1K tokens, output $0.002/1K tokens)
            # ê°„ë‹¨íˆ í‰ê·  $0.00175/1K tokensë¡œ ê³„ì‚°
            cost = (tokens_used / 1000) * 0.00175
            self.stats['total_cost'] += cost
            
            return {
                'success': True,
                'article_id': article.get('article_id', ''),
                'original_title': title,
                'summary': summary,
                'image_url': image_url,
                'category': category,
                'url': url,
                'published_at': published_at,
                'tokens_used': tokens_used,
                'cost': cost,
                'summarized_at': datetime.now().isoformat()
            }
            
        except Exception as e:
            self.stats['error_count'] += 1
            return {
                'success': False,
                'error': str(e),
                'article_id': article.get('article_id', ''),
                'image_url': article.get('image_url', ''),
                'category': article.get('category', ''),
                'url': article.get('url', ''),
                'published_at': article.get('published_at', '')
            }
    
    def summarize_batch(self, articles: List[Dict[str, Any]], 
                       delay: float = 1.0,
                       max_articles: Optional[int] = None) -> List[Dict[str, Any]]:
        """
        ì—¬ëŸ¬ ê¸°ì‚¬ë¥¼ ë°°ì¹˜ë¡œ ìš”ì•½
        
        Args:
            articles: ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸
            delay: ìš”ì²­ ê°„ ëŒ€ê¸° ì‹œê°„ (ì´ˆ, API ì œí•œ ê³ ë ¤)
            max_articles: ìµœëŒ€ ìš”ì•½í•  ê¸°ì‚¬ ìˆ˜ (Noneì´ë©´ ì „ì²´)
            
        Returns:
            ìš”ì•½ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        self.stats['total_articles'] = len(articles)
        
        if max_articles:
            articles = articles[:max_articles]
        
        summaries = []
        total = len(articles)
        
        print(f"\n{'='*70}")
        print(f"ğŸ“ ë‰´ìŠ¤ ìš”ì•½ ì‹œì‘")
        print(f"ì´ ê¸°ì‚¬ ìˆ˜: {total}ê°œ")
        print(f"{'='*70}\n")
        
        for i, article in enumerate(articles, 1):
            article_id = article.get('article_id', 'Unknown')
            title = article.get('title', 'No Title')
            
            print(f"[{i}/{total}] ìš”ì•½ ì¤‘: {article_id} - {title[:50]}...")
            
            result = self.summarize_article(article)
            summaries.append(result)
            
            if result['success']:
                print(f"  âœ… ìš”ì•½ ì™„ë£Œ (í† í°: {result['tokens_used']}, ë¹„ìš©: ${result['cost']:.4f})")
                print(f"  ğŸ“„ ìš”ì•½: {result['summary'][:100]}...")
            else:
                print(f"  âŒ ì˜¤ë¥˜: {result['error']}")
            
            sys.stdout.flush()
            
            # API ì œí•œ ê³ ë ¤í•˜ì—¬ ëŒ€ê¸°
            if i < total:
                time.sleep(delay)
            
            # ì§„í–‰ ìƒí™© (10ê°œë§ˆë‹¤)
            if i % 10 == 0:
                print(f"\nğŸ“Š ì§„í–‰ë¥ : {i}/{total} ({i/total*100:.1f}%)")
                print(f"   ì„±ê³µ: {self.stats['success_count']}ê°œ, ì‹¤íŒ¨: {self.stats['error_count']}ê°œ")
                print(f"   ì´ í† í°: {self.stats['total_tokens_used']}, ì´ ë¹„ìš©: ${self.stats['total_cost']:.4f}\n")
                sys.stdout.flush()
        
        # ìµœì¢… í†µê³„
        print(f"\n{'='*70}")
        print(f"âœ… ìš”ì•½ ì™„ë£Œ!")
        print(f"{'='*70}")
        print(f"ì´ ê¸°ì‚¬: {total}ê°œ")
        print(f"ì„±ê³µ: {self.stats['success_count']}ê°œ")
        print(f"ì‹¤íŒ¨: {self.stats['error_count']}ê°œ")
        print(f"ì„±ê³µë¥ : {self.stats['success_count']/total*100:.1f}%")
        print(f"ì´ í† í° ì‚¬ìš©: {self.stats['total_tokens_used']}")
        print(f"ì´ ë¹„ìš©: ${self.stats['total_cost']:.4f}")
        print(f"{'='*70}\n")
        
        return summaries
    
    def load_articles_from_json(self, filepath: str) -> List[Dict[str, Any]]:
        """
        JSON íŒŒì¼ì—ì„œ ê¸°ì‚¬ ë¡œë“œ
        
        Args:
            filepath: JSON íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸
        """
        with open(filepath, 'r', encoding='utf-8') as f:
            articles = json.load(f)
        
        print(f"ğŸ“‚ íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {filepath}")
        print(f"   ê¸°ì‚¬ ìˆ˜: {len(articles)}ê°œ\n")
        
        return articles
    
    def save_summaries(self, summaries: List[Dict[str, Any]], 
                      output_path: str,
                      original_articles: Optional[List[Dict[str, Any]]] = None):
        """
        ìš”ì•½ ê²°ê³¼ ì €ì¥
        
        Args:
            summaries: ìš”ì•½ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
            original_articles: ì›ë³¸ ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸ (í•¨ê»˜ ì €ì¥í•  ê²½ìš°)
        """
        # ìš”ì•½ ê²°ê³¼ë§Œ ì €ì¥
        if original_articles is None:
            data = {
                'summaries': summaries,
                'metadata': {
                    'total_articles': self.stats['total_articles'],
                    'success_count': self.stats['success_count'],
                    'error_count': self.stats['error_count'],
                    'total_tokens_used': self.stats['total_tokens_used'],
                    'total_cost': self.stats['total_cost'],
                    'created_at': datetime.now().isoformat()
                }
            }
        else:
            # ì›ë³¸ ê¸°ì‚¬ì™€ ìš”ì•½ ê²°ê³¼ë¥¼ ë§¤í•‘í•˜ì—¬ ì €ì¥
            merged_data = []
            summary_dict = {s['article_id']: s for s in summaries}
            
            for article in original_articles:
                article_id = article.get('article_id', '')
                summary_info = summary_dict.get(article_id, {})
                
                merged_article = article.copy()
                merged_article['summary'] = summary_info.get('summary', '')
                merged_article['summary_tokens'] = summary_info.get('tokens_used', 0)
                merged_article['summary_success'] = summary_info.get('success', False)
                merged_article['summarized_at'] = summary_info.get('summarized_at', '')
                
                merged_data.append(merged_article)
            
            data = {
                'articles': merged_data,
                'metadata': {
                    'total_articles': self.stats['total_articles'],
                    'success_count': self.stats['success_count'],
                    'error_count': self.stats['error_count'],
                    'total_tokens_used': self.stats['total_tokens_used'],
                    'total_cost': self.stats['total_cost'],
                    'created_at': datetime.now().isoformat()
                }
            }
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        # JSON íŒŒì¼ ì €ì¥
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ìš”ì•½ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}")
        print(f"   íŒŒì¼ í¬ê¸°: {os.path.getsize(output_path) / 1024:.2f} KB\n")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='OpenAIë¥¼ ì‚¬ìš©í•œ ë‰´ìŠ¤ ê¸°ì‚¬ ìš”ì•½',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # ë‹¨ì¼ íŒŒì¼ ìš”ì•½
  python summarizer.py --input ../DB/crawling/mk_news_economy_20251205_165744.json
  
  # ìµœëŒ€ 10ê°œ ê¸°ì‚¬ë§Œ ìš”ì•½ (í…ŒìŠ¤íŠ¸ìš©)
  python summarizer.py --input ../DB/crawling/mk_news_economy_20251205_165744.json --max-articles 10
  
  # ì›ë³¸ ê¸°ì‚¬ì™€ í•¨ê»˜ ì €ì¥
  python summarizer.py --input ../DB/crawling/mk_news_economy_20251205_165744.json --merge-original
  
  # ì¶œë ¥ ê²½ë¡œ ì§€ì •
  python summarizer.py --input ../DB/crawling/mk_news_economy_20251205_165744.json --output ../DB/summaries/economy_summary.json
        """
    )
    
    parser.add_argument('--input', '-i', type=str, required=True,
                       help='ì…ë ¥ JSON íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--output', '-o', type=str, default=None,
                       help='ì¶œë ¥ JSON íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸: ../DB/summaries/summary_[timestamp].json)')
    parser.add_argument('--max-articles', type=int, default=None,
                       help='ìµœëŒ€ ìš”ì•½í•  ê¸°ì‚¬ ìˆ˜ (ê¸°ë³¸: ì „ì²´)')
    parser.add_argument('--delay', type=float, default=1.0,
                       help='ìš”ì²­ ê°„ ëŒ€ê¸° ì‹œê°„(ì´ˆ) (ê¸°ë³¸: 1.0)')
    parser.add_argument('--merge-original', action='store_true',
                       help='ì›ë³¸ ê¸°ì‚¬ì™€ ìš”ì•½ì„ í•¨ê»˜ ì €ì¥')
    parser.add_argument('--max-tokens', type=int, default=500,
                       help='ìš”ì•½ ìµœëŒ€ í† í° ìˆ˜ (ê¸°ë³¸: 500)')
    
    args = parser.parse_args()
    
    try:
        # Summarizer ìƒì„±
        print("ğŸš€ ë‰´ìŠ¤ ìš”ì•½ ì‹œìŠ¤í…œ ì‹œì‘\n")
        summarizer = NewsSummarizer()
        
        # ê¸°ì‚¬ ë¡œë“œ
        articles = summarizer.load_articles_from_json(args.input)
        
        # ìš”ì•½ ì‹¤í–‰
        summaries = summarizer.summarize_batch(
            articles,
            delay=args.delay,
            max_articles=args.max_articles
        )
        
        # ì¶œë ¥ ê²½ë¡œ ìƒì„±
        if args.output is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            args.output = f"../DB/summaries/summary_{timestamp}.json"
        
        # ê²°ê³¼ ì €ì¥
        original_articles = articles if args.merge_original else None
        summarizer.save_summaries(summaries, args.output, original_articles)
        
        print("âœ… ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
