"""
ëª¨ë“  ì¹´í…Œê³ ë¦¬ 100ê°œì”© ìˆœì°¨ì ìœ¼ë¡œ í¬ë¡¤ë§
"""

import sys
import time
from mk_crawler import MKCrawler, DataStorage, MK_CATEGORIES

sys.stdout.reconfigure(encoding='utf-8')

# ê° ì¹´í…Œê³ ë¦¬ë³„ ì‹œì‘ ë²ˆí˜¸ (2025-12-05 ì—…ë°ì´íŠ¸)
CATEGORY_START_NUMBERS = {
    "economy": 11485597,
    "politics": 11485596,
    "society": 11485590,
    "business": 11485567,
    "realestate": 11485592,
    "stock": 11485514,
    "culture": 11485571,
    "it": 11480509,
    "sports": 11485610,
    "world": 11485582
}

def main():
    print("=" * 70)
    print("ëª¨ë“  ì¹´í…Œê³ ë¦¬ ìˆœì°¨ í¬ë¡¤ë§ ì‹œì‘")
    print("ê° ì¹´í…Œê³ ë¦¬ë‹¹ 50ê°œì”© ìˆ˜ì§‘")
    print("=" * 70)
    print()
    
    crawler = MKCrawler(delay=0.3)
    storage = DataStorage(output_dir="../DB/crawling")
    
    # ì „ì²´ ì¹´í…Œê³ ë¦¬ í¬ë¡¤ë§
    categories_to_crawl = [
        ("economy", "ê²½ì œ"),
        ("politics", "ì •ì¹˜"),
        ("society", "ì‚¬íšŒ"),
        ("world", "êµ­ì œ"),
        ("business", "ê¸°ì—…"),
        ("stock", "ì¦ê¶Œ"),
        ("realestate", "ë¶€ë™ì‚°"),
        ("it", "IT"),
        ("culture", "ë¬¸í™”"),
        ("sports", "ìŠ¤í¬ì¸ ")
    ]
    
    all_results = {}
    
    for category_slug, category_name in categories_to_crawl:
        if category_slug not in CATEGORY_START_NUMBERS:
            print(f"âš ï¸  {category_name} ({category_slug})ì˜ ì‹œì‘ ë²ˆí˜¸ê°€ ì—†ìŠµë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.")
            continue
        
        start_number = CATEGORY_START_NUMBERS[category_slug]
        
        print(f"\n{'='*70}")
        print(f"ì¹´í…Œê³ ë¦¬: {category_name} ({category_slug})")
        print(f"ì‹œì‘ ë²ˆí˜¸: {start_number}")
        print(f"{'='*70}\n")
        sys.stdout.flush()
        
        try:
            articles = crawler.crawl_by_number_range(
                category=category_slug,
                start_number=start_number,
                max_articles=50
            )
            
            all_results[category_slug] = len(articles)
            
            # ê²°ê³¼ ì €ì¥
            if articles:
                from datetime import datetime
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                
                json_file = storage.save_to_json(
                    articles,
                    f"mk_news_{category_slug}_{timestamp}.json"
                )
                csv_file = storage.save_to_csv(
                    articles,
                    f"mk_news_{category_slug}_{timestamp}.csv"
                )
                
                print(f"\nğŸ“ ì €ì¥ ì™„ë£Œ:")
                print(f"  JSON: {json_file}")
                print(f"  CSV: {csv_file}")
                sys.stdout.flush()
            
            # ì¹´í…Œê³ ë¦¬ ê°„ ëŒ€ê¸° (10ì´ˆ)
            if category_slug != categories_to_crawl[-1][0]:
                print(f"\në‹¤ìŒ ì¹´í…Œê³ ë¦¬ë¡œ ì´ë™í•˜ê¸° ì „ 10ì´ˆ ëŒ€ê¸°...")
                sys.stdout.flush()
                time.sleep(10)
                
        except KeyboardInterrupt:
            print(f"\n\nâš ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
            break
        except Exception as e:
            print(f"\nâŒ {category_name} ({category_slug}) ì¹´í…Œê³ ë¦¬ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            all_results[category_slug] = 0
            continue
    
    # ì „ì²´ ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 70)
    print("ì „ì²´ ê²°ê³¼ ìš”ì•½")
    print("=" * 70)
    total_articles = sum(all_results.values())
    for cat_slug, cat_name in categories_to_crawl:
        count = all_results.get(cat_slug, 0)
        print(f"  {cat_name:10s} ({cat_slug:15s}): {count:4d}ê°œ")
    print(f"{'='*70}")
    print(f"  ì´ê³„: {total_articles:4d}ê°œ")
    print("=" * 70)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
